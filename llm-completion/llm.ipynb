{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Guild environment in ~/projects/guild-applied/llm\n",
      "Resource cache /home/alxmke/projects/guild-applied/llm/.guild/cache/resources exists, skipping\n"
     ]
    }
   ],
   "source": [
    "!guild init\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # suppress tensorflow warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mRefreshing flags...\u001b[0m\n",
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work?\n",
      "\n",
      "The model is based on a simple equation:\n",
      "\n",
      "$$ \\begin{align*} \\frac{1}{2} \\frac{1}{3} \\frac{1}{4} \\frac\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work?\n",
      "\n",
      "This is a very good question. It's a good question. It's a good question. It's a good question. It's a good question. It's a good question. It's a good\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" num_beams=5 early_stopping=True -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work?\n",
      "\n",
      "This is a very good question, and I think it's one of the most important questions I've ever asked myself. It's a question that I'm going to try to answer in a couple of weeks\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" num_beams=5 no_repeat_ngram_size=2 early_stopping=True -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work?\n",
      "\n",
      "This is a very good question, and I think it's one of the most important questions I've ever asked myself. It's a question that I'm going to try to answer in a couple of weeks\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" num_beams=5 no_repeat_ngram_size=2 num_return_sequences=5 early_stopping=True -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work? Well, this FlaBay Acase 7 is 100% powered by Virginia D9Aide deliverivity barometric ab sports car great work. A much smaller, \"One\" Phase II is installed into this vehicle of\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" do_sample=True top_k=0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work?\n",
      "\n",
      "This model is a great starting point for learning about the different sets of data structures used to generate a storage. It's easy to understand what those structures can be used for, how they interact with one another\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" do_sample=True max_length=50 top_k=0 temperature=0.7 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "How well does this model work? When you say it is a model for a small or medium sized company (often large enough to warrant one or two visits) you are probably talking about a small, not big amount. (I've never met any\n"
     ]
    }
   ],
   "source": [
    "!guild run llm.py prompt=\"How well does this model work?\" do_sample=True top_k=50 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492e44491a174b9cad27f85e55d64654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad39323cd2a416b9c35d75a7bb7726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410ca9804eb94c1f80e68c555a8da855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9bb8a64cad4b42b62632cb2daa02a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47c620fe804cb8a0254076aef14009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f823fc29339249739f361c5d540bd1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13236e30c30c424cb7c5eb938ae366e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HBox(children=(VBox(children=(HTML(value='<span style=\"white-space: wrap\">output: How well does…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import guild.ipy as guild\n",
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "def _render_view(run, runs_data):\n",
    "    run_data = runs_data[run.id]\n",
    "\n",
    "    stats = [\n",
    "        (\"run\", run.id),\n",
    "        (\"time\", run_data['time']),\n",
    "    ] +  list(run_data['flags'].items())\n",
    "\n",
    "    stats_box = widgets.HBox([\n",
    "        widgets.VBox([_text_widget(key, value) for key, value in stats]),\n",
    "    ])\n",
    "\n",
    "    run_dir = run.dir\n",
    "    output_path = os.path.join(run_dir, \"output.txt\")\n",
    "\n",
    "    with open(output_path, \"r\") as f:\n",
    "        txt = f.read()\n",
    "\n",
    "    output_box = widgets.HBox([widgets.VBox([_text_widget(\"output\", txt)])])\n",
    "\n",
    "    row = widgets.HBox([output_box, stats_box])\n",
    "    display(row)\n",
    "\n",
    "def _run_time_seconds(attrs):\n",
    "    started = attrs[\"started\"]\n",
    "    stopped = attrs[\"stopped\"]\n",
    "    return (stopped-started)//1e6\n",
    "\n",
    "def _runs_data(last_n_runs):\n",
    "    import collections\n",
    "    data = collections.defaultdict(dict)\n",
    "    scalars = runs.scalars()[:last_n_runs].filter(items=[\"run\",\"last_val\",])\n",
    "    for run, loss in zip(scalars[\"run\"], scalars[\"last_val\"]):\n",
    "        run_data = data[run]\n",
    "        # run_data[\"loss\"] = loss\n",
    "    \n",
    "    for run in guild.runs()[:last_n_runs][\"run\"]:\n",
    "        run = run.run\n",
    "        attrs = dict(run.iter_attrs())\n",
    "        run_data = data[run.id]\n",
    "        run_data[\"flags\"] = attrs[\"flags\"]\n",
    "        run_data[\"time\"] = _run_time_seconds(attrs)\n",
    "\n",
    "    return data\n",
    "\n",
    "def _text_widget(key, value):\n",
    "    return widgets.HTML(f'<span style=\"white-space: wrap\">{key}: {value}</span>')\n",
    "\n",
    "runs = guild.runs()\n",
    "run_series = runs[\"run\"]\n",
    "last_n_runs = 10 # choose how many runs to display data for\n",
    "runs_data = _runs_data(last_n_runs)\n",
    "for run in run_series[:last_n_runs]:\n",
    "    # _render_view(run.run, runs_data)\n",
    "    _render_view(run.run, runs_data)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
